{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_SeqtoSeq_pytorch_basic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dab31-VoIBvW"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kNKeHaTAuiK",
        "outputId": "7a65ec44-6d28-47a3-9e6e-d1912a823caa"
      },
      "source": [
        "\"\"\" Neural Machine Translation.\n",
        "    Seq to Seq model.\n",
        "    translate English to Korean.\n",
        "\n",
        "\"\"\"\n",
        "# [batch, seq_len]\n",
        "input_en = ['I PROPOSE to consider the question, ‘Can machines think?’ This should begin with definitions of the meaning of the terms ‘machine’ and ‘think’.',\n",
        "            'A computer would deserve to be called intelligent if it could deceive a human into believing that it was human.',\n",
        "            'Be alone, that is the secret of invention; be alone, that is when ideas are born.',\n",
        "            'I don`t care that they stole my idea . . I care that they don`t have any of their own.',\n",
        "            'If you can’t explain it to a six-year-old, you probably don’t understand it yourself',\n",
        "            'I am enough of an artist to draw freely upon my imagination. Imagination is more important than knowledge. Knowledge is limited. Imagination encircles the world.'\n",
        "            ]\n",
        "\n",
        "input_ko = ['나는 ‘기계들이 생각할 수 있을까?’라는 질문을 고려해볼 것을 제안한다. 이 질문은 `기계’와 `생각’이라는 용어의 의미에 대한 정의에서 시작해야 한다.',\n",
        "            '만약 컴퓨터가 인간을 속여 자신을 마치 인간인 것처럼 믿게 할 수 있다면 컴퓨터를 ‘지능이 있는’ 이라고 부를만한 가치가 충분히 있다.',\n",
        "            '혼자가 되는것, 그것이 발명의 비밀입니다. 혼자가 되는 것, 그것이 아이디어들이 탄생 할 때 입니다.',\n",
        "            '나는 그들이 내 아이디어를 훔치는 것은 신경쓰지 않는다.. 나는 그들이 자기 자신의 것을 가지고 있지 않음을 걱정할뿐 이다.',\n",
        "            '6살 아이에게 설명할 수 없다면, 당신은 분명 스스로 이해하지 못하고 있는 것이다.',\n",
        "            '나는 내 상상력을 자유롭게 그릴 수 있는 충분한 예술가 입니다. 상상력은 지식보다 중요합니다. 지식은 제한되어 있습니다. 상상력은 세상을 에워쌉니다.'\n",
        "            ]\n",
        "\n",
        "for i in input_en:\n",
        "  print(len(i))\n",
        "  print(i)\n",
        "\n",
        "for i in input_ko:\n",
        "  print(len(i))\n",
        "  print(i)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "143\n",
            "I PROPOSE to consider the question, ‘Can machines think?’ This should begin with definitions of the meaning of the terms ‘machine’ and ‘think’.\n",
            "111\n",
            "A computer would deserve to be called intelligent if it could deceive a human into believing that it was human.\n",
            "81\n",
            "Be alone, that is the secret of invention; be alone, that is when ideas are born.\n",
            "86\n",
            "I don`t care that they stole my idea . . I care that they don`t have any of their own.\n",
            "84\n",
            "If you can’t explain it to a six-year-old, you probably don’t understand it yourself\n",
            "161\n",
            "I am enough of an artist to draw freely upon my imagination. Imagination is more important than knowledge. Knowledge is limited. Imagination encircles the world.\n",
            "85\n",
            "나는 ‘기계들이 생각할 수 있을까?’라는 질문을 고려해볼 것을 제안한다. 이 질문은 `기계’와 `생각’이라는 용어의 의미에 대한 정의에서 시작해야 한다.\n",
            "75\n",
            "만약 컴퓨터가 인간을 속여 자신을 마치 인간인 것처럼 믿게 할 수 있다면 컴퓨터를 ‘지능이 있는’ 이라고 부를만한 가치가 충분히 있다.\n",
            "56\n",
            "혼자가 되는것, 그것이 발명의 비밀입니다. 혼자가 되는 것, 그것이 아이디어들이 탄생 할 때 입니다.\n",
            "69\n",
            "나는 그들이 내 아이디어를 훔치는 것은 신경쓰지 않는다.. 나는 그들이 자기 자신의 것을 가지고 있지 않음을 걱정할뿐 이다.\n",
            "46\n",
            "6살 아이에게 설명할 수 없다면, 당신은 분명 스스로 이해하지 못하고 있는 것이다.\n",
            "83\n",
            "나는 내 상상력을 자유롭게 그릴 수 있는 충분한 예술가 입니다. 상상력은 지식보다 중요합니다. 지식은 제한되어 있습니다. 상상력은 세상을 에워쌉니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0x51RfKIGSb",
        "outputId": "7ecc10c6-ef25-4ce1-b281-43899c73c7f1"
      },
      "source": [
        "def basic_tokenizer_space(sentence): # Basic tokenizer. split by space.\n",
        "  tok_sentence = [[word for word in sentence[j].split(' ')] for j in range(len(sentence))]\n",
        "  return tok_sentence\n",
        "\n",
        "tok_input_en = basic_tokenizer_space(input_en)\n",
        "tok_input_ko = basic_tokenizer_space(input_ko)\n",
        "print(tok_input_en)\n",
        "print(tok_input_ko)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['I', 'PROPOSE', 'to', 'consider', 'the', 'question,', '‘Can', 'machines', 'think?’', 'This', 'should', 'begin', 'with', 'definitions', 'of', 'the', 'meaning', 'of', 'the', 'terms', '‘machine’', 'and', '‘think’.'], ['A', 'computer', 'would', 'deserve', 'to', 'be', 'called', 'intelligent', 'if', 'it', 'could', 'deceive', 'a', 'human', 'into', 'believing', 'that', 'it', 'was', 'human.'], ['Be', 'alone,', 'that', 'is', 'the', 'secret', 'of', 'invention;', 'be', 'alone,', 'that', 'is', 'when', 'ideas', 'are', 'born.'], ['I', 'don`t', 'care', 'that', 'they', 'stole', 'my', 'idea', '.', '.', 'I', 'care', 'that', 'they', 'don`t', 'have', 'any', 'of', 'their', 'own.'], ['If', 'you', 'can’t', 'explain', 'it', 'to', 'a', 'six-year-old,', 'you', 'probably', 'don’t', 'understand', 'it', 'yourself'], ['I', 'am', 'enough', 'of', 'an', 'artist', 'to', 'draw', 'freely', 'upon', 'my', 'imagination.', 'Imagination', 'is', 'more', 'important', 'than', 'knowledge.', 'Knowledge', 'is', 'limited.', 'Imagination', 'encircles', 'the', 'world.']]\n",
            "[['나는', '‘기계들이', '생각할', '수', '있을까?’라는', '질문을', '고려해볼', '것을', '제안한다.', '이', '질문은', '`기계’와', '`생각’이라는', '용어의', '의미에', '대한', '정의에서', '시작해야', '한다.'], ['만약', '컴퓨터가', '인간을', '속여', '자신을', '마치', '인간인', '것처럼', '믿게', '할', '수', '있다면', '컴퓨터를', '‘지능이', '있는’', '이라고', '부를만한', '가치가', '충분히', '있다.'], ['혼자가', '되는것,', '그것이', '발명의', '비밀입니다.', '혼자가', '되는', '것,', '그것이', '아이디어들이', '탄생', '할', '때', '입니다.'], ['나는', '그들이', '내', '아이디어를', '훔치는', '것은', '신경쓰지', '않는다..', '나는', '그들이', '자기', '자신의', '것을', '가지고', '있지', '않음을', '걱정할뿐', '이다.'], ['6살', '아이에게', '설명할', '수', '없다면,', '당신은', '분명', '스스로', '이해하지', '못하고', '있는', '것이다.'], ['나는', '내', '상상력을', '자유롭게', '그릴', '수', '있는', '충분한', '예술가', '입니다.', '상상력은', '지식보다', '중요합니다.', '지식은', '제한되어', '있습니다.', '상상력은', '세상을', '에워쌉니다.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5_f3X4iIJRS",
        "outputId": "3a4bd52d-51e0-4c71-e625-f94e69c9a77b"
      },
      "source": [
        "vocab_word2index = {'<PAD>': 0, '<BOS>': 1, '<EOS>': 2} # Begin of sentence: [BOS], End of sentence: [EOS]\n",
        "vocab_index2word = {0: '<PAD>', 1: '<BOS>', 2: '<BOS>'}\n",
        "\n",
        "def make_vocabulary(tok_sentence):\n",
        "  cur_index = len(vocab_word2index)\n",
        "  for s in tok_sentence:\n",
        "    for w in s:\n",
        "      if w not in vocab_word2index:\n",
        "        vocab_word2index[w] = cur_index\n",
        "        vocab_index2word[cur_index] = w\n",
        "        cur_index += 1\n",
        "\n",
        "make_vocabulary(tok_input_en)\n",
        "make_vocabulary(tok_input_ko)\n",
        "print(vocab_word2index)\n",
        "print(vocab_index2word)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<PAD>': 0, '<BOS>': 1, '<EOS>': 2, 'I': 3, 'PROPOSE': 4, 'to': 5, 'consider': 6, 'the': 7, 'question,': 8, '‘Can': 9, 'machines': 10, 'think?’': 11, 'This': 12, 'should': 13, 'begin': 14, 'with': 15, 'definitions': 16, 'of': 17, 'meaning': 18, 'terms': 19, '‘machine’': 20, 'and': 21, '‘think’.': 22, 'A': 23, 'computer': 24, 'would': 25, 'deserve': 26, 'be': 27, 'called': 28, 'intelligent': 29, 'if': 30, 'it': 31, 'could': 32, 'deceive': 33, 'a': 34, 'human': 35, 'into': 36, 'believing': 37, 'that': 38, 'was': 39, 'human.': 40, 'Be': 41, 'alone,': 42, 'is': 43, 'secret': 44, 'invention;': 45, 'when': 46, 'ideas': 47, 'are': 48, 'born.': 49, 'don`t': 50, 'care': 51, 'they': 52, 'stole': 53, 'my': 54, 'idea': 55, '.': 56, 'have': 57, 'any': 58, 'their': 59, 'own.': 60, 'If': 61, 'you': 62, 'can’t': 63, 'explain': 64, 'six-year-old,': 65, 'probably': 66, 'don’t': 67, 'understand': 68, 'yourself': 69, 'am': 70, 'enough': 71, 'an': 72, 'artist': 73, 'draw': 74, 'freely': 75, 'upon': 76, 'imagination.': 77, 'Imagination': 78, 'more': 79, 'important': 80, 'than': 81, 'knowledge.': 82, 'Knowledge': 83, 'limited.': 84, 'encircles': 85, 'world.': 86, '나는': 87, '‘기계들이': 88, '생각할': 89, '수': 90, '있을까?’라는': 91, '질문을': 92, '고려해볼': 93, '것을': 94, '제안한다.': 95, '이': 96, '질문은': 97, '`기계’와': 98, '`생각’이라는': 99, '용어의': 100, '의미에': 101, '대한': 102, '정의에서': 103, '시작해야': 104, '한다.': 105, '만약': 106, '컴퓨터가': 107, '인간을': 108, '속여': 109, '자신을': 110, '마치': 111, '인간인': 112, '것처럼': 113, '믿게': 114, '할': 115, '있다면': 116, '컴퓨터를': 117, '‘지능이': 118, '있는’': 119, '이라고': 120, '부를만한': 121, '가치가': 122, '충분히': 123, '있다.': 124, '혼자가': 125, '되는것,': 126, '그것이': 127, '발명의': 128, '비밀입니다.': 129, '되는': 130, '것,': 131, '아이디어들이': 132, '탄생': 133, '때': 134, '입니다.': 135, '그들이': 136, '내': 137, '아이디어를': 138, '훔치는': 139, '것은': 140, '신경쓰지': 141, '않는다..': 142, '자기': 143, '자신의': 144, '가지고': 145, '있지': 146, '않음을': 147, '걱정할뿐': 148, '이다.': 149, '6살': 150, '아이에게': 151, '설명할': 152, '없다면,': 153, '당신은': 154, '분명': 155, '스스로': 156, '이해하지': 157, '못하고': 158, '있는': 159, '것이다.': 160, '상상력을': 161, '자유롭게': 162, '그릴': 163, '충분한': 164, '예술가': 165, '상상력은': 166, '지식보다': 167, '중요합니다.': 168, '지식은': 169, '제한되어': 170, '있습니다.': 171, '세상을': 172, '에워쌉니다.': 173}\n",
            "{0: '<PAD>', 1: '<BOS>', 2: '<BOS>', 3: 'I', 4: 'PROPOSE', 5: 'to', 6: 'consider', 7: 'the', 8: 'question,', 9: '‘Can', 10: 'machines', 11: 'think?’', 12: 'This', 13: 'should', 14: 'begin', 15: 'with', 16: 'definitions', 17: 'of', 18: 'meaning', 19: 'terms', 20: '‘machine’', 21: 'and', 22: '‘think’.', 23: 'A', 24: 'computer', 25: 'would', 26: 'deserve', 27: 'be', 28: 'called', 29: 'intelligent', 30: 'if', 31: 'it', 32: 'could', 33: 'deceive', 34: 'a', 35: 'human', 36: 'into', 37: 'believing', 38: 'that', 39: 'was', 40: 'human.', 41: 'Be', 42: 'alone,', 43: 'is', 44: 'secret', 45: 'invention;', 46: 'when', 47: 'ideas', 48: 'are', 49: 'born.', 50: 'don`t', 51: 'care', 52: 'they', 53: 'stole', 54: 'my', 55: 'idea', 56: '.', 57: 'have', 58: 'any', 59: 'their', 60: 'own.', 61: 'If', 62: 'you', 63: 'can’t', 64: 'explain', 65: 'six-year-old,', 66: 'probably', 67: 'don’t', 68: 'understand', 69: 'yourself', 70: 'am', 71: 'enough', 72: 'an', 73: 'artist', 74: 'draw', 75: 'freely', 76: 'upon', 77: 'imagination.', 78: 'Imagination', 79: 'more', 80: 'important', 81: 'than', 82: 'knowledge.', 83: 'Knowledge', 84: 'limited.', 85: 'encircles', 86: 'world.', 87: '나는', 88: '‘기계들이', 89: '생각할', 90: '수', 91: '있을까?’라는', 92: '질문을', 93: '고려해볼', 94: '것을', 95: '제안한다.', 96: '이', 97: '질문은', 98: '`기계’와', 99: '`생각’이라는', 100: '용어의', 101: '의미에', 102: '대한', 103: '정의에서', 104: '시작해야', 105: '한다.', 106: '만약', 107: '컴퓨터가', 108: '인간을', 109: '속여', 110: '자신을', 111: '마치', 112: '인간인', 113: '것처럼', 114: '믿게', 115: '할', 116: '있다면', 117: '컴퓨터를', 118: '‘지능이', 119: '있는’', 120: '이라고', 121: '부를만한', 122: '가치가', 123: '충분히', 124: '있다.', 125: '혼자가', 126: '되는것,', 127: '그것이', 128: '발명의', 129: '비밀입니다.', 130: '되는', 131: '것,', 132: '아이디어들이', 133: '탄생', 134: '때', 135: '입니다.', 136: '그들이', 137: '내', 138: '아이디어를', 139: '훔치는', 140: '것은', 141: '신경쓰지', 142: '않는다..', 143: '자기', 144: '자신의', 145: '가지고', 146: '있지', 147: '않음을', 148: '걱정할뿐', 149: '이다.', 150: '6살', 151: '아이에게', 152: '설명할', 153: '없다면,', 154: '당신은', 155: '분명', 156: '스스로', 157: '이해하지', 158: '못하고', 159: '있는', 160: '것이다.', 161: '상상력을', 162: '자유롭게', 163: '그릴', 164: '충분한', 165: '예술가', 166: '상상력은', 167: '지식보다', 168: '중요합니다.', 169: '지식은', 170: '제한되어', 171: '있습니다.', 172: '세상을', 173: '에워쌉니다.'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGc2uCQ9PFC1",
        "outputId": "5788ee13-8851-4dde-feab-e3d235adad61"
      },
      "source": [
        "def word_to_index(tok_sentence):\n",
        "  input_w2i = [[vocab_word2index[word] for word in tok_sentence[i]] for i in range(len(tok_sentence))]\n",
        "  return input_w2i\n",
        "\n",
        "w2i_input_en = word_to_index(tok_input_en)\n",
        "w2i_input_ko = word_to_index(tok_input_ko)\n",
        "\n",
        "print(w2i_input_en)\n",
        "print(w2i_input_ko)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 7, 18, 17, 7, 19, 20, 21, 22], [23, 24, 25, 26, 5, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 31, 39, 40], [41, 42, 38, 43, 7, 44, 17, 45, 27, 42, 38, 43, 46, 47, 48, 49], [3, 50, 51, 38, 52, 53, 54, 55, 56, 56, 3, 51, 38, 52, 50, 57, 58, 17, 59, 60], [61, 62, 63, 64, 31, 5, 34, 65, 62, 66, 67, 68, 31, 69], [3, 70, 71, 17, 72, 73, 5, 74, 75, 76, 54, 77, 78, 43, 79, 80, 81, 82, 83, 43, 84, 78, 85, 7, 86]]\n",
            "[[87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], [106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 90, 116, 117, 118, 119, 120, 121, 122, 123, 124], [125, 126, 127, 128, 129, 125, 130, 131, 127, 132, 133, 115, 134, 135], [87, 136, 137, 138, 139, 140, 141, 142, 87, 136, 143, 144, 94, 145, 146, 147, 148, 149], [150, 151, 152, 90, 153, 154, 155, 156, 157, 158, 159, 160], [87, 137, 161, 162, 163, 90, 159, 164, 165, 135, 166, 167, 168, 169, 170, 171, 166, 172, 173]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLW_rj1XTeYE",
        "outputId": "403fbfb0-4440-4434-a8f3-6ca709cabdb3"
      },
      "source": [
        "def index_to_word(tok_sentence):\n",
        "  input_i2w = [[vocab_index2word[word] for word in tok_sentence[i]] for i in range(len(tok_sentence))]\n",
        "  return input_i2w\n",
        "\n",
        "i2w_input_en = index_to_word(w2i_input_en)\n",
        "i2w_input_ko = index_to_word(w2i_input_ko)\n",
        "\n",
        "print(i2w_input_en)\n",
        "print(i2w_input_ko)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['I', 'PROPOSE', 'to', 'consider', 'the', 'question,', '‘Can', 'machines', 'think?’', 'This', 'should', 'begin', 'with', 'definitions', 'of', 'the', 'meaning', 'of', 'the', 'terms', '‘machine’', 'and', '‘think’.'], ['A', 'computer', 'would', 'deserve', 'to', 'be', 'called', 'intelligent', 'if', 'it', 'could', 'deceive', 'a', 'human', 'into', 'believing', 'that', 'it', 'was', 'human.'], ['Be', 'alone,', 'that', 'is', 'the', 'secret', 'of', 'invention;', 'be', 'alone,', 'that', 'is', 'when', 'ideas', 'are', 'born.'], ['I', 'don`t', 'care', 'that', 'they', 'stole', 'my', 'idea', '.', '.', 'I', 'care', 'that', 'they', 'don`t', 'have', 'any', 'of', 'their', 'own.'], ['If', 'you', 'can’t', 'explain', 'it', 'to', 'a', 'six-year-old,', 'you', 'probably', 'don’t', 'understand', 'it', 'yourself'], ['I', 'am', 'enough', 'of', 'an', 'artist', 'to', 'draw', 'freely', 'upon', 'my', 'imagination.', 'Imagination', 'is', 'more', 'important', 'than', 'knowledge.', 'Knowledge', 'is', 'limited.', 'Imagination', 'encircles', 'the', 'world.']]\n",
            "[['나는', '‘기계들이', '생각할', '수', '있을까?’라는', '질문을', '고려해볼', '것을', '제안한다.', '이', '질문은', '`기계’와', '`생각’이라는', '용어의', '의미에', '대한', '정의에서', '시작해야', '한다.'], ['만약', '컴퓨터가', '인간을', '속여', '자신을', '마치', '인간인', '것처럼', '믿게', '할', '수', '있다면', '컴퓨터를', '‘지능이', '있는’', '이라고', '부를만한', '가치가', '충분히', '있다.'], ['혼자가', '되는것,', '그것이', '발명의', '비밀입니다.', '혼자가', '되는', '것,', '그것이', '아이디어들이', '탄생', '할', '때', '입니다.'], ['나는', '그들이', '내', '아이디어를', '훔치는', '것은', '신경쓰지', '않는다..', '나는', '그들이', '자기', '자신의', '것을', '가지고', '있지', '않음을', '걱정할뿐', '이다.'], ['6살', '아이에게', '설명할', '수', '없다면,', '당신은', '분명', '스스로', '이해하지', '못하고', '있는', '것이다.'], ['나는', '내', '상상력을', '자유롭게', '그릴', '수', '있는', '충분한', '예술가', '입니다.', '상상력은', '지식보다', '중요합니다.', '지식은', '제한되어', '있습니다.', '상상력은', '세상을', '에워쌉니다.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwshyO-iVTQk",
        "outputId": "78eb23aa-df98-4e42-9ca1-df5f886c1432"
      },
      "source": [
        "def basic_tokenizer_space(sentence, flag): # add flag.\n",
        "  if 'BOS'== flag:\n",
        "    tok_sentence = [[word for word in ['<BOS>'] + sentence[j].split(' ')] for j in range(len(sentence))]\n",
        "  else:\n",
        "    tok_sentence = [[word for word in sentence[j].split(' ') + ['<EOS>']] for j in range(len(sentence))]\n",
        "  return tok_sentence\n",
        "\n",
        "def add_eos(sentence):\n",
        "  tok_input = basic_tokenizer_space(sentence, 'EOS')\n",
        "  return (tok_input)\n",
        "\n",
        "def add_bos(sentence):\n",
        "  tok_input = basic_tokenizer_space(sentence, 'BOS')\n",
        "  return (tok_input)\n",
        "\n",
        "encoder_input = add_eos(input_en) # \n",
        "decoder_input = add_bos(input_ko) #\n",
        "decoder_target = add_eos(input_ko) # for teacher forcing\n",
        "\n",
        "print(encoder_input)\n",
        "print(decoder_input)\n",
        "print(decoder_target)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['I', 'PROPOSE', 'to', 'consider', 'the', 'question,', '‘Can', 'machines', 'think?’', 'This', 'should', 'begin', 'with', 'definitions', 'of', 'the', 'meaning', 'of', 'the', 'terms', '‘machine’', 'and', '‘think’.', '<EOS>'], ['A', 'computer', 'would', 'deserve', 'to', 'be', 'called', 'intelligent', 'if', 'it', 'could', 'deceive', 'a', 'human', 'into', 'believing', 'that', 'it', 'was', 'human.', '<EOS>'], ['Be', 'alone,', 'that', 'is', 'the', 'secret', 'of', 'invention;', 'be', 'alone,', 'that', 'is', 'when', 'ideas', 'are', 'born.', '<EOS>'], ['I', 'don`t', 'care', 'that', 'they', 'stole', 'my', 'idea', '.', '.', 'I', 'care', 'that', 'they', 'don`t', 'have', 'any', 'of', 'their', 'own.', '<EOS>'], ['If', 'you', 'can’t', 'explain', 'it', 'to', 'a', 'six-year-old,', 'you', 'probably', 'don’t', 'understand', 'it', 'yourself', '<EOS>'], ['I', 'am', 'enough', 'of', 'an', 'artist', 'to', 'draw', 'freely', 'upon', 'my', 'imagination.', 'Imagination', 'is', 'more', 'important', 'than', 'knowledge.', 'Knowledge', 'is', 'limited.', 'Imagination', 'encircles', 'the', 'world.', '<EOS>']]\n",
            "[['<BOS>', '나는', '‘기계들이', '생각할', '수', '있을까?’라는', '질문을', '고려해볼', '것을', '제안한다.', '이', '질문은', '`기계’와', '`생각’이라는', '용어의', '의미에', '대한', '정의에서', '시작해야', '한다.'], ['<BOS>', '만약', '컴퓨터가', '인간을', '속여', '자신을', '마치', '인간인', '것처럼', '믿게', '할', '수', '있다면', '컴퓨터를', '‘지능이', '있는’', '이라고', '부를만한', '가치가', '충분히', '있다.'], ['<BOS>', '혼자가', '되는것,', '그것이', '발명의', '비밀입니다.', '혼자가', '되는', '것,', '그것이', '아이디어들이', '탄생', '할', '때', '입니다.'], ['<BOS>', '나는', '그들이', '내', '아이디어를', '훔치는', '것은', '신경쓰지', '않는다..', '나는', '그들이', '자기', '자신의', '것을', '가지고', '있지', '않음을', '걱정할뿐', '이다.'], ['<BOS>', '6살', '아이에게', '설명할', '수', '없다면,', '당신은', '분명', '스스로', '이해하지', '못하고', '있는', '것이다.'], ['<BOS>', '나는', '내', '상상력을', '자유롭게', '그릴', '수', '있는', '충분한', '예술가', '입니다.', '상상력은', '지식보다', '중요합니다.', '지식은', '제한되어', '있습니다.', '상상력은', '세상을', '에워쌉니다.']]\n",
            "[['나는', '‘기계들이', '생각할', '수', '있을까?’라는', '질문을', '고려해볼', '것을', '제안한다.', '이', '질문은', '`기계’와', '`생각’이라는', '용어의', '의미에', '대한', '정의에서', '시작해야', '한다.', '<EOS>'], ['만약', '컴퓨터가', '인간을', '속여', '자신을', '마치', '인간인', '것처럼', '믿게', '할', '수', '있다면', '컴퓨터를', '‘지능이', '있는’', '이라고', '부를만한', '가치가', '충분히', '있다.', '<EOS>'], ['혼자가', '되는것,', '그것이', '발명의', '비밀입니다.', '혼자가', '되는', '것,', '그것이', '아이디어들이', '탄생', '할', '때', '입니다.', '<EOS>'], ['나는', '그들이', '내', '아이디어를', '훔치는', '것은', '신경쓰지', '않는다..', '나는', '그들이', '자기', '자신의', '것을', '가지고', '있지', '않음을', '걱정할뿐', '이다.', '<EOS>'], ['6살', '아이에게', '설명할', '수', '없다면,', '당신은', '분명', '스스로', '이해하지', '못하고', '있는', '것이다.', '<EOS>'], ['나는', '내', '상상력을', '자유롭게', '그릴', '수', '있는', '충분한', '예술가', '입니다.', '상상력은', '지식보다', '중요합니다.', '지식은', '제한되어', '있습니다.', '상상력은', '세상을', '에워쌉니다.', '<EOS>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRQBy54ger0k"
      },
      "source": [
        "encoder_input = word_to_index(encoder_input)\n",
        "decoder_input = word_to_index(decoder_input)\n",
        "decoder_target = word_to_index(decoder_target)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTBjEB4TgrwV",
        "outputId": "fa009c3b-c063-401e-fefb-cd4514c5370c"
      },
      "source": [
        "print(encoder_input)\n",
        "print(decoder_input)\n",
        "print(decoder_target)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 7, 18, 17, 7, 19, 20, 21, 22, 2], [23, 24, 25, 26, 5, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 31, 39, 40, 2], [41, 42, 38, 43, 7, 44, 17, 45, 27, 42, 38, 43, 46, 47, 48, 49, 2], [3, 50, 51, 38, 52, 53, 54, 55, 56, 56, 3, 51, 38, 52, 50, 57, 58, 17, 59, 60, 2], [61, 62, 63, 64, 31, 5, 34, 65, 62, 66, 67, 68, 31, 69, 2], [3, 70, 71, 17, 72, 73, 5, 74, 75, 76, 54, 77, 78, 43, 79, 80, 81, 82, 83, 43, 84, 78, 85, 7, 86, 2]]\n",
            "[[1, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], [1, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 90, 116, 117, 118, 119, 120, 121, 122, 123, 124], [1, 125, 126, 127, 128, 129, 125, 130, 131, 127, 132, 133, 115, 134, 135], [1, 87, 136, 137, 138, 139, 140, 141, 142, 87, 136, 143, 144, 94, 145, 146, 147, 148, 149], [1, 150, 151, 152, 90, 153, 154, 155, 156, 157, 158, 159, 160], [1, 87, 137, 161, 162, 163, 90, 159, 164, 165, 135, 166, 167, 168, 169, 170, 171, 166, 172, 173]]\n",
            "[[87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 2], [106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 90, 116, 117, 118, 119, 120, 121, 122, 123, 124, 2], [125, 126, 127, 128, 129, 125, 130, 131, 127, 132, 133, 115, 134, 135, 2], [87, 136, 137, 138, 139, 140, 141, 142, 87, 136, 143, 144, 94, 145, 146, 147, 148, 149, 2], [150, 151, 152, 90, 153, 154, 155, 156, 157, 158, 159, 160, 2], [87, 137, 161, 162, 163, 90, 159, 164, 165, 135, 166, 167, 168, 169, 170, 171, 166, 172, 173, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbpodwKNcUWe",
        "outputId": "80ed10e5-0109-40d1-b511-059ba8a137e4"
      },
      "source": [
        "def add_padding(index_sentence):\n",
        "  padd_input = []\n",
        "  for s in index_sentence:\n",
        "      padd_input.append(torch.LongTensor(s))\n",
        "  inputs = torch.nn.utils.rnn.pad_sequence(padd_input, batch_first=True, padding_value=0)\n",
        "  \n",
        "  return inputs\n",
        "\n",
        "encoder_input = add_padding(encoder_input)\n",
        "decoder_input = add_padding(decoder_input)\n",
        "decoder_target = add_padding(decoder_target)\n",
        "print(encoder_input.size())\n",
        "print(encoder_input)\n",
        "print(decoder_input.size())\n",
        "print(decoder_input)\n",
        "print(decoder_target.size())\n",
        "print(decoder_target)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6, 26])\n",
            "tensor([[ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,  7, 18, 17,\n",
            "          7, 19, 20, 21, 22,  2,  0,  0],\n",
            "        [23, 24, 25, 26,  5, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 31,\n",
            "         39, 40,  2,  0,  0,  0,  0,  0],\n",
            "        [41, 42, 38, 43,  7, 44, 17, 45, 27, 42, 38, 43, 46, 47, 48, 49,  2,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [ 3, 50, 51, 38, 52, 53, 54, 55, 56, 56,  3, 51, 38, 52, 50, 57, 58, 17,\n",
            "         59, 60,  2,  0,  0,  0,  0,  0],\n",
            "        [61, 62, 63, 64, 31,  5, 34, 65, 62, 66, 67, 68, 31, 69,  2,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [ 3, 70, 71, 17, 72, 73,  5, 74, 75, 76, 54, 77, 78, 43, 79, 80, 81, 82,\n",
            "         83, 43, 84, 78, 85,  7, 86,  2]])\n",
            "torch.Size([6, 21])\n",
            "tensor([[  1,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
            "         100, 101, 102, 103, 104, 105,   0],\n",
            "        [  1, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,  90, 116, 117,\n",
            "         118, 119, 120, 121, 122, 123, 124],\n",
            "        [  1, 125, 126, 127, 128, 129, 125, 130, 131, 127, 132, 133, 115, 134,\n",
            "         135,   0,   0,   0,   0,   0,   0],\n",
            "        [  1,  87, 136, 137, 138, 139, 140, 141, 142,  87, 136, 143, 144,  94,\n",
            "         145, 146, 147, 148, 149,   0,   0],\n",
            "        [  1, 150, 151, 152,  90, 153, 154, 155, 156, 157, 158, 159, 160,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0],\n",
            "        [  1,  87, 137, 161, 162, 163,  90, 159, 164, 165, 135, 166, 167, 168,\n",
            "         169, 170, 171, 166, 172, 173,   0]])\n",
            "torch.Size([6, 21])\n",
            "tensor([[ 87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,\n",
            "         101, 102, 103, 104, 105,   2,   0],\n",
            "        [106, 107, 108, 109, 110, 111, 112, 113, 114, 115,  90, 116, 117, 118,\n",
            "         119, 120, 121, 122, 123, 124,   2],\n",
            "        [125, 126, 127, 128, 129, 125, 130, 131, 127, 132, 133, 115, 134, 135,\n",
            "           2,   0,   0,   0,   0,   0,   0],\n",
            "        [ 87, 136, 137, 138, 139, 140, 141, 142,  87, 136, 143, 144,  94, 145,\n",
            "         146, 147, 148, 149,   2,   0,   0],\n",
            "        [150, 151, 152,  90, 153, 154, 155, 156, 157, 158, 159, 160,   2,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0],\n",
            "        [ 87, 137, 161, 162, 163,  90, 159, 164, 165, 135, 166, 167, 168, 169,\n",
            "         170, 171, 166, 172, 173,   2,   0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSKBKJoVN74a"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, vocabulary_size, hidden_size):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(vocabulary_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "\n",
        "  def forward(self, sentence, h):\n",
        "    x = self.embedding(sentence) #[batch, seq_length, embedding_hidden]\n",
        "    encoder_out, h_out  = self.gru(x, h)\n",
        "    return encoder_out, h_out\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    h0 = torch.zeros(1, batch_size, self.hidden_size)# [num_layer, batch_size, hidden_size]\n",
        "    return h0"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgvJ0ewMugsj"
      },
      "source": [
        "vocabulary_size = len(vocab_index2word)\n",
        "hidden_size = 256\n",
        "batch_size = encoder_input.size(0)\n",
        "\n",
        "seq2seq_encoder = Encoder(vocabulary_size, hidden_size)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFpzUqjj2pc6",
        "outputId": "17f8be4e-e4dd-453c-f8d9-a6b28722fc99"
      },
      "source": [
        "h0 = seq2seq_encoder.init_hidden(batch_size)\n",
        "encoder_out, encoder_h = seq2seq_encoder(encoder_input, h0)\n",
        "print(encoder_out)\n",
        "print(encoder_h)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.0578e-01, -4.2334e-01,  9.1939e-02,  ...,  1.1392e-01,\n",
            "          -1.9570e-01,  3.0483e-02],\n",
            "         [-1.2534e-01, -5.7273e-01,  2.5832e-01,  ..., -1.4612e-01,\n",
            "           1.0154e-01, -1.3361e-01],\n",
            "         [-4.3737e-02, -1.3441e-01, -5.1799e-02,  ..., -3.7719e-02,\n",
            "           4.3107e-01, -1.6470e-02],\n",
            "         ...,\n",
            "         [-3.2394e-01, -1.7356e-01,  4.0364e-01,  ..., -1.0096e-01,\n",
            "          -2.4934e-01, -2.8686e-01],\n",
            "         [-1.9364e-01, -2.6060e-01,  3.1201e-01,  ..., -7.1571e-02,\n",
            "          -1.9597e-01, -1.1875e-01],\n",
            "         [-9.3884e-02, -3.3563e-01,  2.4027e-01,  ..., -4.5202e-02,\n",
            "          -2.0424e-01, -1.1985e-04]],\n",
            "\n",
            "        [[ 1.6644e-01, -1.5644e-01,  4.9700e-02,  ..., -2.0275e-01,\n",
            "           2.7537e-03, -2.2857e-01],\n",
            "         [-1.9407e-01, -6.0694e-01, -2.8372e-01,  ..., -4.7299e-01,\n",
            "          -1.9072e-01,  7.6128e-02],\n",
            "         [ 8.1878e-02, -2.3193e-02, -1.8616e-01,  ..., -4.6087e-01,\n",
            "           2.0897e-01,  1.9428e-01],\n",
            "         ...,\n",
            "         [ 2.0073e-02, -3.9180e-01,  1.6538e-01,  ..., -4.8383e-02,\n",
            "          -1.4724e-01, -2.7868e-03],\n",
            "         [ 5.6550e-02, -4.2481e-01,  1.4717e-01,  ..., -3.5094e-02,\n",
            "          -1.8975e-01,  8.8805e-02],\n",
            "         [ 8.1032e-02, -4.4450e-01,  1.3346e-01,  ..., -2.5678e-02,\n",
            "          -2.1772e-01,  1.4931e-01]],\n",
            "\n",
            "        [[ 1.8398e-01, -1.6493e-01, -3.5389e-01,  ..., -1.0554e-01,\n",
            "           6.5815e-01, -1.9612e-01],\n",
            "         [ 5.9736e-02, -3.6805e-01, -2.7114e-01,  ..., -2.3233e-01,\n",
            "           2.8799e-01,  4.2356e-01],\n",
            "         [-4.5930e-02,  1.5456e-01, -4.5128e-01,  ...,  1.1404e-01,\n",
            "           2.0400e-03,  2.1422e-01],\n",
            "         ...,\n",
            "         [ 1.1165e-01, -4.6120e-01,  1.2388e-01,  ...,  6.4438e-02,\n",
            "          -2.4479e-01,  2.3165e-01],\n",
            "         [ 1.1658e-01, -4.6527e-01,  1.1897e-01,  ...,  5.4441e-02,\n",
            "          -2.5098e-01,  2.4339e-01],\n",
            "         [ 1.1984e-01, -4.6767e-01,  1.1597e-01,  ...,  4.6604e-02,\n",
            "          -2.5511e-01,  2.5079e-01]],\n",
            "\n",
            "        [[ 1.0578e-01, -4.2334e-01,  9.1939e-02,  ...,  1.1392e-01,\n",
            "          -1.9570e-01,  3.0483e-02],\n",
            "         [-4.4579e-01, -3.4319e-01,  4.1399e-01,  ...,  2.8267e-01,\n",
            "          -5.1286e-01, -1.2972e-01],\n",
            "         [-4.1587e-01,  8.3446e-03,  2.4228e-01,  ...,  5.8290e-01,\n",
            "          -1.2256e-01,  2.0628e-02],\n",
            "         ...,\n",
            "         [ 6.2526e-02, -3.6608e-01,  1.3638e-01,  ...,  7.9255e-02,\n",
            "          -2.2161e-01,  1.4828e-01],\n",
            "         [ 8.3662e-02, -4.0821e-01,  1.2489e-01,  ...,  7.0063e-02,\n",
            "          -2.3596e-01,  1.9536e-01],\n",
            "         [ 9.8685e-02, -4.3311e-01,  1.1754e-01,  ...,  6.0379e-02,\n",
            "          -2.4620e-01,  2.2264e-01]],\n",
            "\n",
            "        [[ 2.0058e-02, -5.4044e-01, -1.4216e-01,  ...,  1.7979e-01,\n",
            "           2.8203e-02,  1.0938e-01],\n",
            "         [-2.2110e-02, -5.9171e-01, -2.6347e-01,  ..., -1.5747e-01,\n",
            "           1.8455e-01, -2.3211e-02],\n",
            "         [ 1.2640e-01, -3.9930e-01, -2.7786e-01,  ..., -3.2162e-01,\n",
            "          -1.8777e-01, -1.1065e-01],\n",
            "         ...,\n",
            "         [ 1.2574e-01, -4.6675e-01,  1.0931e-01,  ...,  1.1102e-02,\n",
            "          -2.6305e-01,  2.4505e-01],\n",
            "         [ 1.2666e-01, -4.6826e-01,  1.0948e-01,  ...,  1.2423e-02,\n",
            "          -2.6374e-01,  2.5042e-01],\n",
            "         [ 1.2710e-01, -4.6926e-01,  1.0967e-01,  ...,  1.3689e-02,\n",
            "          -2.6418e-01,  2.5388e-01]],\n",
            "\n",
            "        [[ 1.0578e-01, -4.2334e-01,  9.1939e-02,  ...,  1.1392e-01,\n",
            "          -1.9570e-01,  3.0483e-02],\n",
            "         [-2.2502e-01, -1.6032e-01, -1.1744e-01,  ...,  5.5667e-02,\n",
            "           9.6324e-03, -1.9330e-01],\n",
            "         [-3.9862e-01, -7.3561e-02,  1.1844e-01,  ..., -2.6577e-01,\n",
            "           1.9945e-01, -5.9271e-01],\n",
            "         ...,\n",
            "         [ 3.5613e-01,  3.2508e-01, -3.4719e-01,  ...,  5.5697e-02,\n",
            "          -6.0613e-02,  3.8763e-02],\n",
            "         [ 1.4432e-01, -7.1368e-02, -1.0032e-01,  ..., -3.1547e-01,\n",
            "          -3.1231e-01,  1.5664e-01],\n",
            "         [-1.1644e-01, -8.5817e-02,  2.3702e-01,  ..., -1.3311e-01,\n",
            "          -2.8162e-01, -3.2640e-01]]], grad_fn=<TransposeBackward1>)\n",
            "tensor([[[-9.3884e-02, -3.3563e-01,  2.4027e-01,  ..., -4.5202e-02,\n",
            "          -2.0424e-01, -1.1985e-04],\n",
            "         [ 8.1032e-02, -4.4450e-01,  1.3346e-01,  ..., -2.5678e-02,\n",
            "          -2.1772e-01,  1.4931e-01],\n",
            "         [ 1.1984e-01, -4.6767e-01,  1.1597e-01,  ...,  4.6604e-02,\n",
            "          -2.5511e-01,  2.5079e-01],\n",
            "         [ 9.8685e-02, -4.3311e-01,  1.1754e-01,  ...,  6.0379e-02,\n",
            "          -2.4620e-01,  2.2264e-01],\n",
            "         [ 1.2710e-01, -4.6926e-01,  1.0967e-01,  ...,  1.3689e-02,\n",
            "          -2.6418e-01,  2.5388e-01],\n",
            "         [-1.1644e-01, -8.5817e-02,  2.3702e-01,  ..., -1.3311e-01,\n",
            "          -2.8162e-01, -3.2640e-01]]], grad_fn=<StackBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X75rOIE4NRx"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, vocabulary_size, hidden_size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(vocabulary_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, vocabulary_size)\n",
        "    \n",
        "  def forward(self, sentence, encoder_h):\n",
        "    x = self.embedding(sentence.view(-1, 1)) #[batch, seq_length, embedding_hidden]\n",
        "    decoder_out, h_out  = self.gru(x, encoder_h)\n",
        "    decoder_out = self.fc(decoder_out)\n",
        "    decoder_out = F.softmax(decoder_out, dim=-1)\n",
        "    return decoder_out, h_out\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_3B1OFC39Pq"
      },
      "source": [
        "seq2seq_decoder = Decoder(vocabulary_size, hidden_size)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvnEB6hn7yxy",
        "outputId": "76ed9a26-2e9e-47c7-e087-56079ed195b3"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "seq_length = decoder_input.size(1)\n",
        "h_in = encoder_h\n",
        "loss = 0\n",
        "for i in range(seq_length): # teacher forcing.\n",
        "  decoder_out, h_out = seq2seq_decoder(decoder_input[:,i], h_in)\n",
        "  h_in = h_out\n",
        "  mask = torch.zeros_like(decoder_target[:,i]) # <pad>로 채워진 부분 loss를 무시하기 위한 mask.\n",
        "  mask = torch.eq(decoder_target[:,i], mask)\n",
        "  decoder_target[:,i].masked_fill_(mask, -1)\n",
        "  loss += criterion(decoder_out.squeeze(1), decoder_target[:,i])\n",
        "total_loss = loss/seq_length\n",
        "print(total_loss)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(5.1593, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0f8Z7Fu8nIO"
      },
      "source": [
        "def train(encoder_input, decoder_input, decoder_target, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        " \n",
        "  batch_size = encoder_input.size(0)\n",
        "  seq_length = decoder_input.size(1)\n",
        "  \n",
        "  h0 = encoder.init_hidden(batch_size)\n",
        "  encoder_out, encoder_h = encoder(encoder_input, h0)\n",
        "\n",
        "  h_in = encoder_h\n",
        "  loss = 0\n",
        "  for i in range(seq_length): # teacher forcing.\n",
        "    decoder_out, h_out = decoder(decoder_input[:,i].contiguous(), h_in)\n",
        "    h_in = h_out\n",
        "    mask = torch.zeros_like(decoder_target[:,i].contiguous()) # <pad>로 채워진 부분 loss를 무시하기 위한 mask.\n",
        "    mask = torch.eq(decoder_target[:,i].contiguous(), mask)\n",
        "    decoder_target[:,i].contiguous().masked_fill_(mask, -1)\n",
        "    loss += criterion(decoder_out.squeeze(1), decoder_target[:,i].contiguous())\n",
        "\n",
        "  total_loss = loss/seq_length\n",
        "  encoder_optimizer.zero_grad()\n",
        "  decoder_optimizer.zero_grad()\n",
        "  total_loss.backward()\n",
        "  encoder_optimizer.step()\n",
        "  decoder_optimizer.step()\n",
        "  return total_loss"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ENxjmIZoMGr"
      },
      "source": [
        "def main():\n",
        "  vocabulary_size = len(vocab_index2word)\n",
        "  hidden_size = 256\n",
        "  learning_rate = 0.0001\n",
        "  epoch = 50\n",
        "  criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "  encoder = Encoder(vocabulary_size, hidden_size)\n",
        "  decoder = Decoder(vocabulary_size, hidden_size)\n",
        "\n",
        "  encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "  decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "  for i in range(epoch):\n",
        "    loss = train(encoder_input, decoder_input, decoder_target, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "    print(loss)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyZfClYWqq89",
        "outputId": "0dc8b057-0f40-4afa-f994-7cbdab7a77a6"
      },
      "source": [
        "main()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(5.1591, grad_fn=<DivBackward0>)\n",
            "tensor(5.1589, grad_fn=<DivBackward0>)\n",
            "tensor(5.1588, grad_fn=<DivBackward0>)\n",
            "tensor(5.1586, grad_fn=<DivBackward0>)\n",
            "tensor(5.1584, grad_fn=<DivBackward0>)\n",
            "tensor(5.1583, grad_fn=<DivBackward0>)\n",
            "tensor(5.1581, grad_fn=<DivBackward0>)\n",
            "tensor(5.1579, grad_fn=<DivBackward0>)\n",
            "tensor(5.1577, grad_fn=<DivBackward0>)\n",
            "tensor(5.1575, grad_fn=<DivBackward0>)\n",
            "tensor(5.1573, grad_fn=<DivBackward0>)\n",
            "tensor(5.1571, grad_fn=<DivBackward0>)\n",
            "tensor(5.1568, grad_fn=<DivBackward0>)\n",
            "tensor(5.1566, grad_fn=<DivBackward0>)\n",
            "tensor(5.1563, grad_fn=<DivBackward0>)\n",
            "tensor(5.1560, grad_fn=<DivBackward0>)\n",
            "tensor(5.1557, grad_fn=<DivBackward0>)\n",
            "tensor(5.1554, grad_fn=<DivBackward0>)\n",
            "tensor(5.1550, grad_fn=<DivBackward0>)\n",
            "tensor(5.1546, grad_fn=<DivBackward0>)\n",
            "tensor(5.1541, grad_fn=<DivBackward0>)\n",
            "tensor(5.1536, grad_fn=<DivBackward0>)\n",
            "tensor(5.1531, grad_fn=<DivBackward0>)\n",
            "tensor(5.1525, grad_fn=<DivBackward0>)\n",
            "tensor(5.1518, grad_fn=<DivBackward0>)\n",
            "tensor(5.1510, grad_fn=<DivBackward0>)\n",
            "tensor(5.1502, grad_fn=<DivBackward0>)\n",
            "tensor(5.1492, grad_fn=<DivBackward0>)\n",
            "tensor(5.1482, grad_fn=<DivBackward0>)\n",
            "tensor(5.1470, grad_fn=<DivBackward0>)\n",
            "tensor(5.1456, grad_fn=<DivBackward0>)\n",
            "tensor(5.1441, grad_fn=<DivBackward0>)\n",
            "tensor(5.1424, grad_fn=<DivBackward0>)\n",
            "tensor(5.1405, grad_fn=<DivBackward0>)\n",
            "tensor(5.1385, grad_fn=<DivBackward0>)\n",
            "tensor(5.1362, grad_fn=<DivBackward0>)\n",
            "tensor(5.1338, grad_fn=<DivBackward0>)\n",
            "tensor(5.1312, grad_fn=<DivBackward0>)\n",
            "tensor(5.1285, grad_fn=<DivBackward0>)\n",
            "tensor(5.1257, grad_fn=<DivBackward0>)\n",
            "tensor(5.1228, grad_fn=<DivBackward0>)\n",
            "tensor(5.1199, grad_fn=<DivBackward0>)\n",
            "tensor(5.1170, grad_fn=<DivBackward0>)\n",
            "tensor(5.1142, grad_fn=<DivBackward0>)\n",
            "tensor(5.1115, grad_fn=<DivBackward0>)\n",
            "tensor(5.1089, grad_fn=<DivBackward0>)\n",
            "tensor(5.1065, grad_fn=<DivBackward0>)\n",
            "tensor(5.1043, grad_fn=<DivBackward0>)\n",
            "tensor(5.1022, grad_fn=<DivBackward0>)\n",
            "tensor(5.1003, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJGB9KLdquYF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
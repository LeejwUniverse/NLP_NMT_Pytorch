{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_SeqtoSeq_pytorch_basic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dab31-VoIBvW"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kNKeHaTAuiK",
        "outputId": "8b5c85f7-9701-4f1b-dfc0-6464c6c88186"
      },
      "source": [
        "\"\"\" Neural Machine Translation.\n",
        "    Seq to Seq model.\n",
        "    translate English to Korean.\n",
        "\n",
        "\"\"\"\n",
        "# [batch, seq_len]\n",
        "input_en = ['I PROPOSE to consider the question, ‘Can machines think?’ This should begin with definitions of the meaning of the terms ‘machine’ and ‘think’.',\n",
        "            'A computer would deserve to be called intelligent if it could deceive a human into believing that it was human.',\n",
        "            'Be alone, that is the secret of invention; be alone, that is when ideas are born.',\n",
        "            'I don`t care that they stole my idea . . I care that they don`t have any of their own.',\n",
        "            'If you can’t explain it to a six-year-old, you probably don’t understand it yourself',\n",
        "            'I am enough of an artist to draw freely upon my imagination. Imagination is more important than knowledge. Knowledge is limited. Imagination encircles the world.'\n",
        "            ]\n",
        "\n",
        "input_ko = ['나는 ‘기계들이 생각할 수 있을까?’라는 질문을 고려해볼 것을 제안한다. 이 질문은 `기계’와 `생각’이라는 용어의 의미에 대한 정의에서 시작해야 한다.',\n",
        "            '만약 컴퓨터가 인간을 속여 자신을 마치 인간인 것처럼 믿게 할 수 있다면 컴퓨터를 ‘지능이 있는’ 이라고 부를만한 가치가 충분히 있다.',\n",
        "            '혼자가 되는것, 그것이 발명의 비밀입니다. 혼자가 되는 것, 그것이 아이디어들이 탄생 할 때 입니다.',\n",
        "            '나는 그들이 내 아이디어를 훔치는 것은 신경쓰지 않는다.. 나는 그들이 자기 자신의 것을 가지고 있지 않음을 걱정할뿐 이다.',\n",
        "            '6살 아이에게 설명할 수 없다면, 당신은 분명 스스로 이해하지 못하고 있는 것이다.',\n",
        "            '나는 내 상상력을 자유롭게 그릴 수 있는 충분한 예술가 입니다. 상상력은 지식보다 중요합니다. 지식은 제한되어 있습니다. 상상력은 세상을 에워쌉니다.'\n",
        "            ]\n",
        "\n",
        "for i in input_en:\n",
        "  print(len(i))\n",
        "  print(i)\n",
        "\n",
        "for i in input_ko:\n",
        "  print(len(i))\n",
        "  print(i)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "143\n",
            "I PROPOSE to consider the question, ‘Can machines think?’ This should begin with definitions of the meaning of the terms ‘machine’ and ‘think’.\n",
            "111\n",
            "A computer would deserve to be called intelligent if it could deceive a human into believing that it was human.\n",
            "81\n",
            "Be alone, that is the secret of invention; be alone, that is when ideas are born.\n",
            "86\n",
            "I don`t care that they stole my idea . . I care that they don`t have any of their own.\n",
            "84\n",
            "If you can’t explain it to a six-year-old, you probably don’t understand it yourself\n",
            "161\n",
            "I am enough of an artist to draw freely upon my imagination. Imagination is more important than knowledge. Knowledge is limited. Imagination encircles the world.\n",
            "85\n",
            "나는 ‘기계들이 생각할 수 있을까?’라는 질문을 고려해볼 것을 제안한다. 이 질문은 `기계’와 `생각’이라는 용어의 의미에 대한 정의에서 시작해야 한다.\n",
            "75\n",
            "만약 컴퓨터가 인간을 속여 자신을 마치 인간인 것처럼 믿게 할 수 있다면 컴퓨터를 ‘지능이 있는’ 이라고 부를만한 가치가 충분히 있다.\n",
            "56\n",
            "혼자가 되는것, 그것이 발명의 비밀입니다. 혼자가 되는 것, 그것이 아이디어들이 탄생 할 때 입니다.\n",
            "69\n",
            "나는 그들이 내 아이디어를 훔치는 것은 신경쓰지 않는다.. 나는 그들이 자기 자신의 것을 가지고 있지 않음을 걱정할뿐 이다.\n",
            "46\n",
            "6살 아이에게 설명할 수 없다면, 당신은 분명 스스로 이해하지 못하고 있는 것이다.\n",
            "83\n",
            "나는 내 상상력을 자유롭게 그릴 수 있는 충분한 예술가 입니다. 상상력은 지식보다 중요합니다. 지식은 제한되어 있습니다. 상상력은 세상을 에워쌉니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0x51RfKIGSb",
        "outputId": "ded70d07-de63-4b03-9142-e7841ffac506"
      },
      "source": [
        "def basic_tokenizer_space(sentence): # Basic tokenizer. split by space.\n",
        "  tok_sentence = [[word for word in sentence[j].split(' ')] for j in range(len(sentence))]\n",
        "  return tok_sentence\n",
        "\n",
        "tok_input_en = basic_tokenizer_space(input_en)\n",
        "tok_input_ko = basic_tokenizer_space(input_ko)\n",
        "print(tok_input_en)\n",
        "print(tok_input_ko)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['I', 'PROPOSE', 'to', 'consider', 'the', 'question,', '‘Can', 'machines', 'think?’', 'This', 'should', 'begin', 'with', 'definitions', 'of', 'the', 'meaning', 'of', 'the', 'terms', '‘machine’', 'and', '‘think’.'], ['A', 'computer', 'would', 'deserve', 'to', 'be', 'called', 'intelligent', 'if', 'it', 'could', 'deceive', 'a', 'human', 'into', 'believing', 'that', 'it', 'was', 'human.'], ['Be', 'alone,', 'that', 'is', 'the', 'secret', 'of', 'invention;', 'be', 'alone,', 'that', 'is', 'when', 'ideas', 'are', 'born.'], ['I', 'don`t', 'care', 'that', 'they', 'stole', 'my', 'idea', '.', '.', 'I', 'care', 'that', 'they', 'don`t', 'have', 'any', 'of', 'their', 'own.'], ['If', 'you', 'can’t', 'explain', 'it', 'to', 'a', 'six-year-old,', 'you', 'probably', 'don’t', 'understand', 'it', 'yourself'], ['I', 'am', 'enough', 'of', 'an', 'artist', 'to', 'draw', 'freely', 'upon', 'my', 'imagination.', 'Imagination', 'is', 'more', 'important', 'than', 'knowledge.', 'Knowledge', 'is', 'limited.', 'Imagination', 'encircles', 'the', 'world.']]\n",
            "[['나는', '‘기계들이', '생각할', '수', '있을까?’라는', '질문을', '고려해볼', '것을', '제안한다.', '이', '질문은', '`기계’와', '`생각’이라는', '용어의', '의미에', '대한', '정의에서', '시작해야', '한다.'], ['만약', '컴퓨터가', '인간을', '속여', '자신을', '마치', '인간인', '것처럼', '믿게', '할', '수', '있다면', '컴퓨터를', '‘지능이', '있는’', '이라고', '부를만한', '가치가', '충분히', '있다.'], ['혼자가', '되는것,', '그것이', '발명의', '비밀입니다.', '혼자가', '되는', '것,', '그것이', '아이디어들이', '탄생', '할', '때', '입니다.'], ['나는', '그들이', '내', '아이디어를', '훔치는', '것은', '신경쓰지', '않는다..', '나는', '그들이', '자기', '자신의', '것을', '가지고', '있지', '않음을', '걱정할뿐', '이다.'], ['6살', '아이에게', '설명할', '수', '없다면,', '당신은', '분명', '스스로', '이해하지', '못하고', '있는', '것이다.'], ['나는', '내', '상상력을', '자유롭게', '그릴', '수', '있는', '충분한', '예술가', '입니다.', '상상력은', '지식보다', '중요합니다.', '지식은', '제한되어', '있습니다.', '상상력은', '세상을', '에워쌉니다.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5_f3X4iIJRS",
        "outputId": "8b4c1ec2-709b-4369-f58c-0cdd67987328"
      },
      "source": [
        "vocab_word2index = {'<PAD>': 0, '<BOS>': 1, '<EOS>': 2} # Begin of sentence: [BOS], End of sentence: [EOS]\n",
        "vocab_index2word = {0: '<PAD>', 1: '<BOS>', 2: '<EOS>'}\n",
        "\n",
        "def make_vocabulary(tok_sentence):\n",
        "  cur_index = len(vocab_word2index)\n",
        "  for s in tok_sentence:\n",
        "    for w in s:\n",
        "      if w not in vocab_word2index:\n",
        "        vocab_word2index[w] = cur_index\n",
        "        vocab_index2word[cur_index] = w\n",
        "        cur_index += 1\n",
        "\n",
        "make_vocabulary(tok_input_en)\n",
        "make_vocabulary(tok_input_ko)\n",
        "print(vocab_word2index)\n",
        "print(vocab_index2word)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'<PAD>': 0, '<BOS>': 1, '<EOS>': 2, 'I': 3, 'PROPOSE': 4, 'to': 5, 'consider': 6, 'the': 7, 'question,': 8, '‘Can': 9, 'machines': 10, 'think?’': 11, 'This': 12, 'should': 13, 'begin': 14, 'with': 15, 'definitions': 16, 'of': 17, 'meaning': 18, 'terms': 19, '‘machine’': 20, 'and': 21, '‘think’.': 22, 'A': 23, 'computer': 24, 'would': 25, 'deserve': 26, 'be': 27, 'called': 28, 'intelligent': 29, 'if': 30, 'it': 31, 'could': 32, 'deceive': 33, 'a': 34, 'human': 35, 'into': 36, 'believing': 37, 'that': 38, 'was': 39, 'human.': 40, 'Be': 41, 'alone,': 42, 'is': 43, 'secret': 44, 'invention;': 45, 'when': 46, 'ideas': 47, 'are': 48, 'born.': 49, 'don`t': 50, 'care': 51, 'they': 52, 'stole': 53, 'my': 54, 'idea': 55, '.': 56, 'have': 57, 'any': 58, 'their': 59, 'own.': 60, 'If': 61, 'you': 62, 'can’t': 63, 'explain': 64, 'six-year-old,': 65, 'probably': 66, 'don’t': 67, 'understand': 68, 'yourself': 69, 'am': 70, 'enough': 71, 'an': 72, 'artist': 73, 'draw': 74, 'freely': 75, 'upon': 76, 'imagination.': 77, 'Imagination': 78, 'more': 79, 'important': 80, 'than': 81, 'knowledge.': 82, 'Knowledge': 83, 'limited.': 84, 'encircles': 85, 'world.': 86, '나는': 87, '‘기계들이': 88, '생각할': 89, '수': 90, '있을까?’라는': 91, '질문을': 92, '고려해볼': 93, '것을': 94, '제안한다.': 95, '이': 96, '질문은': 97, '`기계’와': 98, '`생각’이라는': 99, '용어의': 100, '의미에': 101, '대한': 102, '정의에서': 103, '시작해야': 104, '한다.': 105, '만약': 106, '컴퓨터가': 107, '인간을': 108, '속여': 109, '자신을': 110, '마치': 111, '인간인': 112, '것처럼': 113, '믿게': 114, '할': 115, '있다면': 116, '컴퓨터를': 117, '‘지능이': 118, '있는’': 119, '이라고': 120, '부를만한': 121, '가치가': 122, '충분히': 123, '있다.': 124, '혼자가': 125, '되는것,': 126, '그것이': 127, '발명의': 128, '비밀입니다.': 129, '되는': 130, '것,': 131, '아이디어들이': 132, '탄생': 133, '때': 134, '입니다.': 135, '그들이': 136, '내': 137, '아이디어를': 138, '훔치는': 139, '것은': 140, '신경쓰지': 141, '않는다..': 142, '자기': 143, '자신의': 144, '가지고': 145, '있지': 146, '않음을': 147, '걱정할뿐': 148, '이다.': 149, '6살': 150, '아이에게': 151, '설명할': 152, '없다면,': 153, '당신은': 154, '분명': 155, '스스로': 156, '이해하지': 157, '못하고': 158, '있는': 159, '것이다.': 160, '상상력을': 161, '자유롭게': 162, '그릴': 163, '충분한': 164, '예술가': 165, '상상력은': 166, '지식보다': 167, '중요합니다.': 168, '지식은': 169, '제한되어': 170, '있습니다.': 171, '세상을': 172, '에워쌉니다.': 173}\n",
            "{0: '<PAD>', 1: '<BOS>', 2: '<EOS>', 3: 'I', 4: 'PROPOSE', 5: 'to', 6: 'consider', 7: 'the', 8: 'question,', 9: '‘Can', 10: 'machines', 11: 'think?’', 12: 'This', 13: 'should', 14: 'begin', 15: 'with', 16: 'definitions', 17: 'of', 18: 'meaning', 19: 'terms', 20: '‘machine’', 21: 'and', 22: '‘think’.', 23: 'A', 24: 'computer', 25: 'would', 26: 'deserve', 27: 'be', 28: 'called', 29: 'intelligent', 30: 'if', 31: 'it', 32: 'could', 33: 'deceive', 34: 'a', 35: 'human', 36: 'into', 37: 'believing', 38: 'that', 39: 'was', 40: 'human.', 41: 'Be', 42: 'alone,', 43: 'is', 44: 'secret', 45: 'invention;', 46: 'when', 47: 'ideas', 48: 'are', 49: 'born.', 50: 'don`t', 51: 'care', 52: 'they', 53: 'stole', 54: 'my', 55: 'idea', 56: '.', 57: 'have', 58: 'any', 59: 'their', 60: 'own.', 61: 'If', 62: 'you', 63: 'can’t', 64: 'explain', 65: 'six-year-old,', 66: 'probably', 67: 'don’t', 68: 'understand', 69: 'yourself', 70: 'am', 71: 'enough', 72: 'an', 73: 'artist', 74: 'draw', 75: 'freely', 76: 'upon', 77: 'imagination.', 78: 'Imagination', 79: 'more', 80: 'important', 81: 'than', 82: 'knowledge.', 83: 'Knowledge', 84: 'limited.', 85: 'encircles', 86: 'world.', 87: '나는', 88: '‘기계들이', 89: '생각할', 90: '수', 91: '있을까?’라는', 92: '질문을', 93: '고려해볼', 94: '것을', 95: '제안한다.', 96: '이', 97: '질문은', 98: '`기계’와', 99: '`생각’이라는', 100: '용어의', 101: '의미에', 102: '대한', 103: '정의에서', 104: '시작해야', 105: '한다.', 106: '만약', 107: '컴퓨터가', 108: '인간을', 109: '속여', 110: '자신을', 111: '마치', 112: '인간인', 113: '것처럼', 114: '믿게', 115: '할', 116: '있다면', 117: '컴퓨터를', 118: '‘지능이', 119: '있는’', 120: '이라고', 121: '부를만한', 122: '가치가', 123: '충분히', 124: '있다.', 125: '혼자가', 126: '되는것,', 127: '그것이', 128: '발명의', 129: '비밀입니다.', 130: '되는', 131: '것,', 132: '아이디어들이', 133: '탄생', 134: '때', 135: '입니다.', 136: '그들이', 137: '내', 138: '아이디어를', 139: '훔치는', 140: '것은', 141: '신경쓰지', 142: '않는다..', 143: '자기', 144: '자신의', 145: '가지고', 146: '있지', 147: '않음을', 148: '걱정할뿐', 149: '이다.', 150: '6살', 151: '아이에게', 152: '설명할', 153: '없다면,', 154: '당신은', 155: '분명', 156: '스스로', 157: '이해하지', 158: '못하고', 159: '있는', 160: '것이다.', 161: '상상력을', 162: '자유롭게', 163: '그릴', 164: '충분한', 165: '예술가', 166: '상상력은', 167: '지식보다', 168: '중요합니다.', 169: '지식은', 170: '제한되어', 171: '있습니다.', 172: '세상을', 173: '에워쌉니다.'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGc2uCQ9PFC1",
        "outputId": "024b250b-c8bc-460d-d9a7-b7a54590caf5"
      },
      "source": [
        "def word_to_index(tok_sentence):\n",
        "  input_w2i = [[vocab_word2index[word] for word in tok_sentence[i]] for i in range(len(tok_sentence))]\n",
        "  return input_w2i\n",
        "\n",
        "w2i_input_en = word_to_index(tok_input_en)\n",
        "w2i_input_ko = word_to_index(tok_input_ko)\n",
        "\n",
        "print(w2i_input_en)\n",
        "print(w2i_input_ko)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 7, 18, 17, 7, 19, 20, 21, 22], [23, 24, 25, 26, 5, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 31, 39, 40], [41, 42, 38, 43, 7, 44, 17, 45, 27, 42, 38, 43, 46, 47, 48, 49], [3, 50, 51, 38, 52, 53, 54, 55, 56, 56, 3, 51, 38, 52, 50, 57, 58, 17, 59, 60], [61, 62, 63, 64, 31, 5, 34, 65, 62, 66, 67, 68, 31, 69], [3, 70, 71, 17, 72, 73, 5, 74, 75, 76, 54, 77, 78, 43, 79, 80, 81, 82, 83, 43, 84, 78, 85, 7, 86]]\n",
            "[[87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], [106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 90, 116, 117, 118, 119, 120, 121, 122, 123, 124], [125, 126, 127, 128, 129, 125, 130, 131, 127, 132, 133, 115, 134, 135], [87, 136, 137, 138, 139, 140, 141, 142, 87, 136, 143, 144, 94, 145, 146, 147, 148, 149], [150, 151, 152, 90, 153, 154, 155, 156, 157, 158, 159, 160], [87, 137, 161, 162, 163, 90, 159, 164, 165, 135, 166, 167, 168, 169, 170, 171, 166, 172, 173]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLW_rj1XTeYE",
        "outputId": "b2cb8168-8acc-4d4a-9e62-52da4935d5bb"
      },
      "source": [
        "def index_to_word(tok_sentence):\n",
        "  input_i2w = [[vocab_index2word[word] for word in tok_sentence[i]] for i in range(len(tok_sentence))]\n",
        "  return input_i2w\n",
        "\n",
        "i2w_input_en = index_to_word(w2i_input_en)\n",
        "i2w_input_ko = index_to_word(w2i_input_ko)\n",
        "\n",
        "print(i2w_input_en)\n",
        "print(i2w_input_ko)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['I', 'PROPOSE', 'to', 'consider', 'the', 'question,', '‘Can', 'machines', 'think?’', 'This', 'should', 'begin', 'with', 'definitions', 'of', 'the', 'meaning', 'of', 'the', 'terms', '‘machine’', 'and', '‘think’.'], ['A', 'computer', 'would', 'deserve', 'to', 'be', 'called', 'intelligent', 'if', 'it', 'could', 'deceive', 'a', 'human', 'into', 'believing', 'that', 'it', 'was', 'human.'], ['Be', 'alone,', 'that', 'is', 'the', 'secret', 'of', 'invention;', 'be', 'alone,', 'that', 'is', 'when', 'ideas', 'are', 'born.'], ['I', 'don`t', 'care', 'that', 'they', 'stole', 'my', 'idea', '.', '.', 'I', 'care', 'that', 'they', 'don`t', 'have', 'any', 'of', 'their', 'own.'], ['If', 'you', 'can’t', 'explain', 'it', 'to', 'a', 'six-year-old,', 'you', 'probably', 'don’t', 'understand', 'it', 'yourself'], ['I', 'am', 'enough', 'of', 'an', 'artist', 'to', 'draw', 'freely', 'upon', 'my', 'imagination.', 'Imagination', 'is', 'more', 'important', 'than', 'knowledge.', 'Knowledge', 'is', 'limited.', 'Imagination', 'encircles', 'the', 'world.']]\n",
            "[['나는', '‘기계들이', '생각할', '수', '있을까?’라는', '질문을', '고려해볼', '것을', '제안한다.', '이', '질문은', '`기계’와', '`생각’이라는', '용어의', '의미에', '대한', '정의에서', '시작해야', '한다.'], ['만약', '컴퓨터가', '인간을', '속여', '자신을', '마치', '인간인', '것처럼', '믿게', '할', '수', '있다면', '컴퓨터를', '‘지능이', '있는’', '이라고', '부를만한', '가치가', '충분히', '있다.'], ['혼자가', '되는것,', '그것이', '발명의', '비밀입니다.', '혼자가', '되는', '것,', '그것이', '아이디어들이', '탄생', '할', '때', '입니다.'], ['나는', '그들이', '내', '아이디어를', '훔치는', '것은', '신경쓰지', '않는다..', '나는', '그들이', '자기', '자신의', '것을', '가지고', '있지', '않음을', '걱정할뿐', '이다.'], ['6살', '아이에게', '설명할', '수', '없다면,', '당신은', '분명', '스스로', '이해하지', '못하고', '있는', '것이다.'], ['나는', '내', '상상력을', '자유롭게', '그릴', '수', '있는', '충분한', '예술가', '입니다.', '상상력은', '지식보다', '중요합니다.', '지식은', '제한되어', '있습니다.', '상상력은', '세상을', '에워쌉니다.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwshyO-iVTQk",
        "outputId": "7df257c5-7175-4c3a-cc77-ae66f1574930"
      },
      "source": [
        "def basic_tokenizer_space(sentence, flag): # add flag.\n",
        "  if 'BOS'== flag:\n",
        "    tok_sentence = [[word for word in ['<BOS>'] + sentence[j].split(' ')] for j in range(len(sentence))]\n",
        "  else:\n",
        "    tok_sentence = [[word for word in sentence[j].split(' ') + ['<EOS>']] for j in range(len(sentence))]\n",
        "  return tok_sentence\n",
        "\n",
        "def add_eos(sentence):\n",
        "  tok_input = basic_tokenizer_space(sentence, 'EOS')\n",
        "  return (tok_input)\n",
        "\n",
        "def add_bos(sentence):\n",
        "  tok_input = basic_tokenizer_space(sentence, 'BOS')\n",
        "  return (tok_input)\n",
        "\n",
        "encoder_input = add_eos(input_en) # \n",
        "decoder_input = add_bos(input_ko) #\n",
        "decoder_target = add_eos(input_ko) # for teacher forcing\n",
        "\n",
        "print(encoder_input)\n",
        "print(decoder_input)\n",
        "print(decoder_target)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['I', 'PROPOSE', 'to', 'consider', 'the', 'question,', '‘Can', 'machines', 'think?’', 'This', 'should', 'begin', 'with', 'definitions', 'of', 'the', 'meaning', 'of', 'the', 'terms', '‘machine’', 'and', '‘think’.', '<EOS>'], ['A', 'computer', 'would', 'deserve', 'to', 'be', 'called', 'intelligent', 'if', 'it', 'could', 'deceive', 'a', 'human', 'into', 'believing', 'that', 'it', 'was', 'human.', '<EOS>'], ['Be', 'alone,', 'that', 'is', 'the', 'secret', 'of', 'invention;', 'be', 'alone,', 'that', 'is', 'when', 'ideas', 'are', 'born.', '<EOS>'], ['I', 'don`t', 'care', 'that', 'they', 'stole', 'my', 'idea', '.', '.', 'I', 'care', 'that', 'they', 'don`t', 'have', 'any', 'of', 'their', 'own.', '<EOS>'], ['If', 'you', 'can’t', 'explain', 'it', 'to', 'a', 'six-year-old,', 'you', 'probably', 'don’t', 'understand', 'it', 'yourself', '<EOS>'], ['I', 'am', 'enough', 'of', 'an', 'artist', 'to', 'draw', 'freely', 'upon', 'my', 'imagination.', 'Imagination', 'is', 'more', 'important', 'than', 'knowledge.', 'Knowledge', 'is', 'limited.', 'Imagination', 'encircles', 'the', 'world.', '<EOS>']]\n",
            "[['<BOS>', '나는', '‘기계들이', '생각할', '수', '있을까?’라는', '질문을', '고려해볼', '것을', '제안한다.', '이', '질문은', '`기계’와', '`생각’이라는', '용어의', '의미에', '대한', '정의에서', '시작해야', '한다.'], ['<BOS>', '만약', '컴퓨터가', '인간을', '속여', '자신을', '마치', '인간인', '것처럼', '믿게', '할', '수', '있다면', '컴퓨터를', '‘지능이', '있는’', '이라고', '부를만한', '가치가', '충분히', '있다.'], ['<BOS>', '혼자가', '되는것,', '그것이', '발명의', '비밀입니다.', '혼자가', '되는', '것,', '그것이', '아이디어들이', '탄생', '할', '때', '입니다.'], ['<BOS>', '나는', '그들이', '내', '아이디어를', '훔치는', '것은', '신경쓰지', '않는다..', '나는', '그들이', '자기', '자신의', '것을', '가지고', '있지', '않음을', '걱정할뿐', '이다.'], ['<BOS>', '6살', '아이에게', '설명할', '수', '없다면,', '당신은', '분명', '스스로', '이해하지', '못하고', '있는', '것이다.'], ['<BOS>', '나는', '내', '상상력을', '자유롭게', '그릴', '수', '있는', '충분한', '예술가', '입니다.', '상상력은', '지식보다', '중요합니다.', '지식은', '제한되어', '있습니다.', '상상력은', '세상을', '에워쌉니다.']]\n",
            "[['나는', '‘기계들이', '생각할', '수', '있을까?’라는', '질문을', '고려해볼', '것을', '제안한다.', '이', '질문은', '`기계’와', '`생각’이라는', '용어의', '의미에', '대한', '정의에서', '시작해야', '한다.', '<EOS>'], ['만약', '컴퓨터가', '인간을', '속여', '자신을', '마치', '인간인', '것처럼', '믿게', '할', '수', '있다면', '컴퓨터를', '‘지능이', '있는’', '이라고', '부를만한', '가치가', '충분히', '있다.', '<EOS>'], ['혼자가', '되는것,', '그것이', '발명의', '비밀입니다.', '혼자가', '되는', '것,', '그것이', '아이디어들이', '탄생', '할', '때', '입니다.', '<EOS>'], ['나는', '그들이', '내', '아이디어를', '훔치는', '것은', '신경쓰지', '않는다..', '나는', '그들이', '자기', '자신의', '것을', '가지고', '있지', '않음을', '걱정할뿐', '이다.', '<EOS>'], ['6살', '아이에게', '설명할', '수', '없다면,', '당신은', '분명', '스스로', '이해하지', '못하고', '있는', '것이다.', '<EOS>'], ['나는', '내', '상상력을', '자유롭게', '그릴', '수', '있는', '충분한', '예술가', '입니다.', '상상력은', '지식보다', '중요합니다.', '지식은', '제한되어', '있습니다.', '상상력은', '세상을', '에워쌉니다.', '<EOS>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRQBy54ger0k"
      },
      "source": [
        "encoder_input = word_to_index(encoder_input)\n",
        "decoder_input = word_to_index(decoder_input)\n",
        "decoder_target = word_to_index(decoder_target)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTBjEB4TgrwV",
        "outputId": "a5d8aaca-d86f-48ba-e8a2-5668eeb8b064"
      },
      "source": [
        "print(encoder_input)\n",
        "print(decoder_input)\n",
        "print(decoder_target)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 7, 18, 17, 7, 19, 20, 21, 22, 2], [23, 24, 25, 26, 5, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 31, 39, 40, 2], [41, 42, 38, 43, 7, 44, 17, 45, 27, 42, 38, 43, 46, 47, 48, 49, 2], [3, 50, 51, 38, 52, 53, 54, 55, 56, 56, 3, 51, 38, 52, 50, 57, 58, 17, 59, 60, 2], [61, 62, 63, 64, 31, 5, 34, 65, 62, 66, 67, 68, 31, 69, 2], [3, 70, 71, 17, 72, 73, 5, 74, 75, 76, 54, 77, 78, 43, 79, 80, 81, 82, 83, 43, 84, 78, 85, 7, 86, 2]]\n",
            "[[1, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105], [1, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 90, 116, 117, 118, 119, 120, 121, 122, 123, 124], [1, 125, 126, 127, 128, 129, 125, 130, 131, 127, 132, 133, 115, 134, 135], [1, 87, 136, 137, 138, 139, 140, 141, 142, 87, 136, 143, 144, 94, 145, 146, 147, 148, 149], [1, 150, 151, 152, 90, 153, 154, 155, 156, 157, 158, 159, 160], [1, 87, 137, 161, 162, 163, 90, 159, 164, 165, 135, 166, 167, 168, 169, 170, 171, 166, 172, 173]]\n",
            "[[87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 2], [106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 90, 116, 117, 118, 119, 120, 121, 122, 123, 124, 2], [125, 126, 127, 128, 129, 125, 130, 131, 127, 132, 133, 115, 134, 135, 2], [87, 136, 137, 138, 139, 140, 141, 142, 87, 136, 143, 144, 94, 145, 146, 147, 148, 149, 2], [150, 151, 152, 90, 153, 154, 155, 156, 157, 158, 159, 160, 2], [87, 137, 161, 162, 163, 90, 159, 164, 165, 135, 166, 167, 168, 169, 170, 171, 166, 172, 173, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbpodwKNcUWe",
        "outputId": "32a453ef-d20b-414f-abcb-65c44a3e6be6"
      },
      "source": [
        "def add_padding(index_sentence):\n",
        "  padd_input = []\n",
        "  for s in index_sentence:\n",
        "      padd_input.append(torch.LongTensor(s))\n",
        "  inputs = torch.nn.utils.rnn.pad_sequence(padd_input, batch_first=True, padding_value=0)\n",
        "  \n",
        "  return inputs\n",
        "\n",
        "encoder_input = add_padding(encoder_input)\n",
        "decoder_input = add_padding(decoder_input)\n",
        "decoder_target = add_padding(decoder_target)\n",
        "print(encoder_input.size())\n",
        "print(encoder_input)\n",
        "print(decoder_input.size())\n",
        "print(decoder_input)\n",
        "print(decoder_target.size())\n",
        "print(decoder_target)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6, 26])\n",
            "tensor([[ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,  7, 18, 17,\n",
            "          7, 19, 20, 21, 22,  2,  0,  0],\n",
            "        [23, 24, 25, 26,  5, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 31,\n",
            "         39, 40,  2,  0,  0,  0,  0,  0],\n",
            "        [41, 42, 38, 43,  7, 44, 17, 45, 27, 42, 38, 43, 46, 47, 48, 49,  2,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [ 3, 50, 51, 38, 52, 53, 54, 55, 56, 56,  3, 51, 38, 52, 50, 57, 58, 17,\n",
            "         59, 60,  2,  0,  0,  0,  0,  0],\n",
            "        [61, 62, 63, 64, 31,  5, 34, 65, 62, 66, 67, 68, 31, 69,  2,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [ 3, 70, 71, 17, 72, 73,  5, 74, 75, 76, 54, 77, 78, 43, 79, 80, 81, 82,\n",
            "         83, 43, 84, 78, 85,  7, 86,  2]])\n",
            "torch.Size([6, 21])\n",
            "tensor([[  1,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
            "         100, 101, 102, 103, 104, 105,   0],\n",
            "        [  1, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,  90, 116, 117,\n",
            "         118, 119, 120, 121, 122, 123, 124],\n",
            "        [  1, 125, 126, 127, 128, 129, 125, 130, 131, 127, 132, 133, 115, 134,\n",
            "         135,   0,   0,   0,   0,   0,   0],\n",
            "        [  1,  87, 136, 137, 138, 139, 140, 141, 142,  87, 136, 143, 144,  94,\n",
            "         145, 146, 147, 148, 149,   0,   0],\n",
            "        [  1, 150, 151, 152,  90, 153, 154, 155, 156, 157, 158, 159, 160,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0],\n",
            "        [  1,  87, 137, 161, 162, 163,  90, 159, 164, 165, 135, 166, 167, 168,\n",
            "         169, 170, 171, 166, 172, 173,   0]])\n",
            "torch.Size([6, 21])\n",
            "tensor([[ 87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100,\n",
            "         101, 102, 103, 104, 105,   2,   0],\n",
            "        [106, 107, 108, 109, 110, 111, 112, 113, 114, 115,  90, 116, 117, 118,\n",
            "         119, 120, 121, 122, 123, 124,   2],\n",
            "        [125, 126, 127, 128, 129, 125, 130, 131, 127, 132, 133, 115, 134, 135,\n",
            "           2,   0,   0,   0,   0,   0,   0],\n",
            "        [ 87, 136, 137, 138, 139, 140, 141, 142,  87, 136, 143, 144,  94, 145,\n",
            "         146, 147, 148, 149,   2,   0,   0],\n",
            "        [150, 151, 152,  90, 153, 154, 155, 156, 157, 158, 159, 160,   2,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0],\n",
            "        [ 87, 137, 161, 162, 163,  90, 159, 164, 165, 135, 166, 167, 168, 169,\n",
            "         170, 171, 166, 172, 173,   2,   0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSKBKJoVN74a"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, vocabulary_size, hidden_size):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(vocabulary_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "\n",
        "  def forward(self, sentence, h):\n",
        "    x = self.embedding(sentence) #[batch, seq_length, embedding_hidden]\n",
        "    encoder_out, h_out  = self.gru(x, h)\n",
        "    return encoder_out, h_out\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    h0 = torch.zeros(1, batch_size, self.hidden_size)# [num_layer, batch_size, hidden_size]\n",
        "    return h0"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgvJ0ewMugsj"
      },
      "source": [
        "vocabulary_size = len(vocab_index2word)\n",
        "hidden_size = 256\n",
        "batch_size = encoder_input.size(0)\n",
        "\n",
        "seq2seq_encoder = Encoder(vocabulary_size, hidden_size)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFpzUqjj2pc6",
        "outputId": "2c4a347b-2aa2-4f07-b0e0-d18ffdd45c3e"
      },
      "source": [
        "h0 = seq2seq_encoder.init_hidden(batch_size)\n",
        "encoder_out, encoder_h = seq2seq_encoder(encoder_input, h0)\n",
        "print(encoder_out)\n",
        "print(encoder_h)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-0.3803, -0.0462, -0.0700,  ...,  0.2218, -0.3185, -0.2669],\n",
            "         [ 0.1460, -0.2634, -0.3757,  ..., -0.0204, -0.3092, -0.3942],\n",
            "         [-0.0740, -0.1579, -0.3301,  ...,  0.0277, -0.3904, -0.2140],\n",
            "         ...,\n",
            "         [ 0.2109, -0.0085, -0.0362,  ...,  0.0451, -0.0049,  0.5214],\n",
            "         [ 0.0330, -0.0788,  0.1647,  ...,  0.0676, -0.0078,  0.2110],\n",
            "         [-0.0360, -0.1051,  0.3172,  ...,  0.0543,  0.0223,  0.0337]],\n",
            "\n",
            "        [[-0.2235, -0.1175,  0.1762,  ...,  0.1648,  0.0178,  0.1176],\n",
            "         [-0.1554, -0.0436, -0.3007,  ..., -0.1256, -0.2155, -0.1450],\n",
            "         [-0.4313,  0.5197,  0.3201,  ...,  0.0550,  0.2622, -0.0510],\n",
            "         ...,\n",
            "         [-0.1637, -0.1334,  0.4262,  ..., -0.0155, -0.0044, -0.0615],\n",
            "         [-0.1605, -0.1319,  0.4696,  ..., -0.0100,  0.0506, -0.0987],\n",
            "         [-0.1592, -0.1302,  0.4950,  ..., -0.0048,  0.0927, -0.1162]],\n",
            "\n",
            "        [[ 0.1470, -0.1425, -0.1220,  ..., -0.0445, -0.0412, -0.2181],\n",
            "         [ 0.0323,  0.0140,  0.0171,  ..., -0.0850, -0.0109, -0.0958],\n",
            "         [-0.1415,  0.4274,  0.1652,  ..., -0.1426,  0.1836, -0.1361],\n",
            "         ...,\n",
            "         [-0.1308, -0.1237,  0.5229,  ...,  0.0124,  0.1507, -0.1264],\n",
            "         [-0.1389, -0.1222,  0.5272,  ...,  0.0118,  0.1661, -0.1281],\n",
            "         [-0.1444, -0.1204,  0.5301,  ...,  0.0114,  0.1774, -0.1285]],\n",
            "\n",
            "        [[-0.3803, -0.0462, -0.0700,  ...,  0.2218, -0.3185, -0.2669],\n",
            "         [ 0.1864, -0.2386, -0.2366,  ...,  0.0102, -0.0648, -0.0940],\n",
            "         [ 0.4726, -0.1023, -0.2383,  ...,  0.2719,  0.1407, -0.2029],\n",
            "         ...,\n",
            "         [-0.0516, -0.0895,  0.3819,  ...,  0.0125, -0.0013, -0.0132],\n",
            "         [-0.0739, -0.1091,  0.4466,  ...,  0.0146,  0.0487, -0.0670],\n",
            "         [-0.0941, -0.1187,  0.4837,  ...,  0.0143,  0.0887, -0.0958]],\n",
            "\n",
            "        [[-0.0691, -0.3278, -0.0461,  ...,  0.2584,  0.0302, -0.0059],\n",
            "         [-0.0426, -0.3631, -0.1964,  ...,  0.2570, -0.4396, -0.1356],\n",
            "         [ 0.2314,  0.2303, -0.1536,  ..., -0.1230, -0.0659, -0.1195],\n",
            "         ...,\n",
            "         [-0.1428, -0.1193,  0.5265,  ...,  0.0097,  0.1814, -0.1287],\n",
            "         [-0.1470, -0.1170,  0.5298,  ...,  0.0100,  0.1886, -0.1286],\n",
            "         [-0.1496, -0.1151,  0.5320,  ...,  0.0103,  0.1938, -0.1282]],\n",
            "\n",
            "        [[-0.3803, -0.0462, -0.0700,  ...,  0.2218, -0.3185, -0.2669],\n",
            "         [ 0.0035,  0.2968, -0.1739,  ...,  0.3543,  0.1311, -0.0596],\n",
            "         [-0.1708, -0.1323, -0.3913,  ...,  0.1882,  0.0055, -0.2372],\n",
            "         ...,\n",
            "         [ 0.0824, -0.5567,  0.1478,  ..., -0.0993, -0.2769, -0.0132],\n",
            "         [ 0.3386, -0.2641,  0.3089,  ...,  0.0264,  0.0645,  0.1040],\n",
            "         [ 0.2556, -0.1781,  0.2382,  ..., -0.0880, -0.1130,  0.5168]]],\n",
            "       grad_fn=<TransposeBackward1>)\n",
            "tensor([[[-0.0360, -0.1051,  0.3172,  ...,  0.0543,  0.0223,  0.0337],\n",
            "         [-0.1592, -0.1302,  0.4950,  ..., -0.0048,  0.0927, -0.1162],\n",
            "         [-0.1444, -0.1204,  0.5301,  ...,  0.0114,  0.1774, -0.1285],\n",
            "         [-0.0941, -0.1187,  0.4837,  ...,  0.0143,  0.0887, -0.0958],\n",
            "         [-0.1496, -0.1151,  0.5320,  ...,  0.0103,  0.1938, -0.1282],\n",
            "         [ 0.2556, -0.1781,  0.2382,  ..., -0.0880, -0.1130,  0.5168]]],\n",
            "       grad_fn=<StackBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X75rOIE4NRx"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, vocabulary_size, hidden_size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(vocabulary_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, vocabulary_size)\n",
        "    \n",
        "  def forward(self, sentence, encoder_h):\n",
        "    x = self.embedding(sentence.view(-1, 1)) #[batch, seq_length, embedding_hidden]\n",
        "    decoder_out, h_out  = self.gru(x, encoder_h)\n",
        "    decoder_out = self.fc(decoder_out)\n",
        "    decoder_out = F.softmax(decoder_out, dim=-1)\n",
        "    return decoder_out, h_out\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_3B1OFC39Pq"
      },
      "source": [
        "seq2seq_decoder = Decoder(vocabulary_size, hidden_size)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvnEB6hn7yxy",
        "outputId": "e216181f-40a8-4c63-98e2-044d32d9f5fe"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "seq_length = decoder_input.size(1)\n",
        "h_in = encoder_h\n",
        "loss = 0\n",
        "for i in range(seq_length): # teacher forcing.\n",
        "  decoder_out, h_out = seq2seq_decoder(decoder_input[:,i], h_in)\n",
        "  h_in = h_out\n",
        "  mask = torch.zeros_like(decoder_target[:,i]) # <pad>로 채워진 부분 loss를 무시하기 위한 mask.\n",
        "  mask = torch.eq(decoder_target[:,i], mask)\n",
        "  decoder_target[:,i].masked_fill_(mask, -1)\n",
        "  loss += criterion(decoder_out.squeeze(1), decoder_target[:,i])\n",
        "total_loss = loss/seq_length\n",
        "print(total_loss)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(5.1590, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0f8Z7Fu8nIO"
      },
      "source": [
        "def train(encoder_input, decoder_input, decoder_target, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        " \n",
        "  batch_size = encoder_input.size(0)\n",
        "  seq_length = decoder_input.size(1)\n",
        "  \n",
        "  h0 = encoder.init_hidden(batch_size)\n",
        "  encoder_out, encoder_h = encoder(encoder_input, h0)\n",
        "\n",
        "  h_in = encoder_h\n",
        "  loss = 0\n",
        "  for i in range(seq_length): # teacher forcing.\n",
        "    decoder_out, h_out = decoder(decoder_input[:,i].contiguous(), h_in)\n",
        "    h_in = h_out\n",
        "    mask = torch.zeros_like(decoder_target[:,i].contiguous()) # <pad>로 채워진 부분 loss를 무시하기 위한 mask.\n",
        "    mask = torch.eq(decoder_target[:,i].contiguous(), mask)\n",
        "    decoder_target[:,i].contiguous().masked_fill_(mask, -1)\n",
        "    loss += criterion(decoder_out.squeeze(1), decoder_target[:,i].contiguous())\n",
        "\n",
        "  total_loss = loss/seq_length\n",
        "  encoder_optimizer.zero_grad()\n",
        "  decoder_optimizer.zero_grad()\n",
        "  total_loss.backward()\n",
        "  encoder_optimizer.step()\n",
        "  decoder_optimizer.step()\n",
        "  return total_loss"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o8PNo8K7zfV"
      },
      "source": [
        "def inference(encoder_input, encoder, decoder, max_length):\n",
        "  \n",
        "  output_sentence = []\n",
        "  h0 = encoder.init_hidden(1)\n",
        "  encoder_out, encoder_h = encoder(encoder_input, h0)\n",
        "\n",
        "  h_in = encoder_h\n",
        "\n",
        "  dec_input = '<BOS>'\n",
        "  dec_input = torch.LongTensor([vocab_word2index[dec_input]])\n",
        "  \n",
        "  for i in range(max_length):\n",
        "    decoder_out, h_out = decoder(dec_input, h_in)\n",
        "    dec_input= decoder_out.argmax()\n",
        "    \n",
        "    output_sentence.append(vocab_index2word[dec_input.item()])\n",
        "    if '<EOS>' == vocab_index2word[dec_input.item()]:\n",
        "      break\n",
        "    h_in = h_out\n",
        "\n",
        "  return output_sentence\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ENxjmIZoMGr"
      },
      "source": [
        "def main():\n",
        "  vocabulary_size = len(vocab_index2word)\n",
        "  hidden_size = 256\n",
        "  learning_rate = 0.0001\n",
        "  epoch = 25\n",
        "  max_length = 200\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "  encoder = Encoder(vocabulary_size, hidden_size)\n",
        "  decoder = Decoder(vocabulary_size, hidden_size)\n",
        "\n",
        "  encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "  decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "  for i in range(epoch):\n",
        "    loss = train(encoder_input, decoder_input, decoder_target, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "    print(loss)\n",
        "  \n",
        "  pred_sentence = inference(encoder_input[1].unsqueeze(0), encoder, decoder, max_length)\n",
        "  print(encoder_input[1])\n",
        "  print(pred_sentence)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyZfClYWqq89",
        "outputId": "5137f6f2-5e06-4c34-d5aa-f4231c887973"
      },
      "source": [
        "main()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(5.1593, grad_fn=<DivBackward0>)\n",
            "tensor(5.1591, grad_fn=<DivBackward0>)\n",
            "tensor(5.1590, grad_fn=<DivBackward0>)\n",
            "tensor(5.1588, grad_fn=<DivBackward0>)\n",
            "tensor(5.1587, grad_fn=<DivBackward0>)\n",
            "tensor(5.1586, grad_fn=<DivBackward0>)\n",
            "tensor(5.1584, grad_fn=<DivBackward0>)\n",
            "tensor(5.1582, grad_fn=<DivBackward0>)\n",
            "tensor(5.1581, grad_fn=<DivBackward0>)\n",
            "tensor(5.1579, grad_fn=<DivBackward0>)\n",
            "tensor(5.1577, grad_fn=<DivBackward0>)\n",
            "tensor(5.1575, grad_fn=<DivBackward0>)\n",
            "tensor(5.1573, grad_fn=<DivBackward0>)\n",
            "tensor(5.1571, grad_fn=<DivBackward0>)\n",
            "tensor(5.1569, grad_fn=<DivBackward0>)\n",
            "tensor(5.1567, grad_fn=<DivBackward0>)\n",
            "tensor(5.1565, grad_fn=<DivBackward0>)\n",
            "tensor(5.1562, grad_fn=<DivBackward0>)\n",
            "tensor(5.1560, grad_fn=<DivBackward0>)\n",
            "tensor(5.1557, grad_fn=<DivBackward0>)\n",
            "tensor(5.1554, grad_fn=<DivBackward0>)\n",
            "tensor(5.1551, grad_fn=<DivBackward0>)\n",
            "tensor(5.1547, grad_fn=<DivBackward0>)\n",
            "tensor(5.1543, grad_fn=<DivBackward0>)\n",
            "tensor(5.1539, grad_fn=<DivBackward0>)\n",
            "tensor([23, 24, 25, 26,  5, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 31,\n",
            "        39, 40,  2,  0,  0,  0,  0,  0])\n",
            "['만약', '만약', '인간을', '속여', '자신을', '마치', '마치', '할', '할', '부를만한', '가치가', '<EOS>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJGB9KLdquYF"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}